{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tools.data_setter import cifar_100_setter\n",
    "from models import cifar, imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "teacher = cifar.WideResNet(depth=16, widen_factor=4, num_classes=100)\n",
    "filename = './model_checkpoints/cifar100/None/wrn-16-4/alp_0.1_T_1.0/random_highest_1.0_random_highest_1.0_seed9999.t1'\n",
    "checkpoint = torch.load(filename, map_location=device)['199']\n",
    "teacher.load_state_dict(checkpoint, strict=True)\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders, dataset_size = cifar_100_setter(teacher=teacher,\n",
    "                                             mode=None,\n",
    "                                             batch_size=10,\n",
    "                                             root='/home/osilab7/hdd/cifar',\n",
    "                                             model_name='cifar100/None/wrn-16-4/alp_0.1_T_1.0/random_highest_1.0_random_highest_1.0_seed1.t1',\n",
    "                                             cls_acq='random',\n",
    "                                             cls_order='highest',\n",
    "                                             zeta=1.0,\n",
    "                                             sample_acq='random',\n",
    "                                             sample_order='highest',\n",
    "                                             delta=1.0)\n",
    "\n",
    "sample_lst = next(iter(dataloaders['train']))\n",
    "img_lst = sample_lst[0]\n",
    "label_lst = sample_lst[1]\n",
    "\n",
    "mean = torch.tensor([0.5071, 0.4865, 0.4409]).view(3, 1, 1)\n",
    "std = torch.tensor([0.2673, 0.2564, 0.2762]).view(3, 1, 1)\n",
    "pil_trans = transforms.ToPILImage()\n",
    "\n",
    "original_img_lst = []\n",
    "for s in img_lst:\n",
    "    original_img_lst.append(pil_trans(s*std+mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(img):\n",
    "    probs = torch.softmax(teacher(img.unsqueeze(0)), dim=1)\n",
    "    log_probs = torch.log(probs)\n",
    "    entropy = -torch.sum(probs*log_probs)\n",
    "    \n",
    "    pred_label = torch.argmax(probs).item()\n",
    "    return pred_label, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_img_trans(img_trans=None):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(25, 10))\n",
    "\n",
    "    nrm_trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])])\n",
    "\n",
    "    for idx, (s, l) in enumerate(list(zip(original_img_lst, label_lst))):\n",
    "        # Add trans except for nrm_trans\n",
    "        if img_trans is not None:\n",
    "            trans_s = img_trans(s)\n",
    "        else:\n",
    "            trans_s = s\n",
    "        axes[idx].imshow(trans_s)\n",
    "\n",
    "        # Get entropy after nrm_trans\n",
    "        pred_label, entropy = get_entropy(nrm_trans(trans_s))\n",
    "        axes[idx].set_title('{:.6f} / {}'.format(entropy.item(), l==pred_label))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None\n",
    "plot_per_img_trans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal Flip\n",
    "img_trans = transforms.Compose([transforms.RandomHorizontalFlip(p=1.0)])\n",
    "plot_per_img_trans(img_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop\n",
    "img_trans = transforms.Compose([transforms.RandomCrop(32, padding=4)])\n",
    "plot_per_img_trans(img_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip and Crop\n",
    "img_trans = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                transforms.RandomHorizontalFlip()])\n",
    "plot_per_img_trans(img_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
